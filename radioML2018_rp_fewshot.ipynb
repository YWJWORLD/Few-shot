{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "from pyts.image import RecurrencePlot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import column_or_1d\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# task_generator\n",
    "def mini_imagenet_folders(): # train valid test split\n",
    "    # temp_meatrain = ['8PSK','AM-DSB-WC','BPSK','GMSK','16APSK','64QAM']\n",
    "    # temp_metavalid=['QPSK','AM-SSB-WC','16QAM','32PSK','FM']\n",
    "    # temp_metatest=['OOK','4ASK','16PSK','32APSK','32QAM']\n",
    "    # metatrain_folders=le.transform(temp_meatrain)\n",
    "    # metavalid_folders = le.transform(temp_metavalid)\n",
    "    # metatest_folders=le.transform(temp_metatest)\n",
    "    metatrain_folders = np.random.choice(classes, size=TRAIN_NUM, replace=False)\n",
    "    metavalid_folders = np.random.choice(list(set(classes)-set(metatrain_folders)), size=VALID_NUM, replace=False)\n",
    "    metatest_folders = list(set(classes)-set(metatrain_folders)-set(metavalid_folders))\n",
    "    # metatest_folders = list(set(classes)-set(metatrain_folders))\n",
    "    return list(metatrain_folders), list(metavalid_folders), metatest_folders\n",
    "    # return list(metatrain_folders), list(metatest_folders)\n",
    "\n",
    "class MiniImagenetTask(object):\n",
    "    # support set, query image sampling\n",
    "    def __init__(self, character_folders, num_classes, train_num, test_num):\n",
    "        self.character_folders = character_folders # mods\n",
    "        self.num_classes = num_classes # way\n",
    "        self.train_num = train_num # shot\n",
    "        self.test_num = test_num # query\n",
    "\n",
    "        class_folders = random.sample(self.character_folders,self.num_classes)\n",
    "        # print(class_folders)\n",
    "        self.train_roots= np.array([]).reshape(0,2,len_samples,len_samples)\n",
    "        self.test_roots= np.array([]).reshape(0,2,len_samples,len_samples)\n",
    "        self.train_labels = []\n",
    "        self.test_labels = []\n",
    "        label_enc = MyLabelEncoder()\n",
    "        for c in class_folders:\n",
    "            sample_idx = np.where(Y==c)\n",
    "            # print(sample_idx)\n",
    "            samples = X[sample_idx]\n",
    "            # print(samples.shape)\n",
    "            labels = Y[sample_idx]\n",
    "            \n",
    "            label_enc.fit(labels)\n",
    "            labels = label_enc.transform(labels)\n",
    "            train_samples, test_samples, train_samples_labels, test_samples_labels = train_test_split(\n",
    "                samples, labels, test_size=test_num, train_size=train_num,stratify=labels)\n",
    "    \n",
    "            self.train_roots = np.vstack((self.train_roots,train_samples))\n",
    "            self.test_roots = np.vstack((self.test_roots,test_samples))\n",
    "            self.train_labels.extend(train_samples_labels)\n",
    "            self.test_labels.extend(test_samples_labels)\n",
    "            \n",
    "        \n",
    "        # self.train_roots = np.array(self.train_roots)\n",
    "        # self.test_roots = np.array(self.test_roots)\n",
    "        # self.train_labels = np.array(self.train_labels)\n",
    "        # self.test_labels = np.array(self.test_labels)\n",
    "\n",
    "class FewShotDataset(Dataset):\n",
    "    def __init__(self, task, split='train', transform=None, target_transform=None):\n",
    "        # self.transform = transform # Torch operations on the input image\n",
    "        # self.target_transform = target_transform\n",
    "        self.task = task\n",
    "        self.split = split\n",
    "        self.image_roots = self.task.train_roots if self.split == 'train' else self.task.test_roots\n",
    "        self.labels = self.task.train_labels if self.split == 'train' else self.task.test_labels\n",
    "    def __len__(self):\n",
    "        return len(self.image_roots)\n",
    "    def __getitem__(self, idx):\n",
    "        raise NotImplementedError(\"This is an abstract class. Subclass this class for your particular dataset.\")\n",
    "\n",
    "class MiniImagenet(FewShotDataset):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MiniImagenet, self).__init__(*args, **kwargs)\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.tensor(self.image_roots[idx], dtype=torch.float)\n",
    "        # if self.transform is not None:\n",
    "        #     image = self.transform(image)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.int)\n",
    "        # if self.target_transform is not None:\n",
    "        #     label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "class ClassBalancedSampler(Sampler):\n",
    "    ''' Samples 'num_inst' examples each from 'num_cl' pools\n",
    "        of examples of size 'num_per_class' '''\n",
    "    def __init__(self, num_per_class, num_cl, num_inst,shuffle=True):\n",
    "        self.num_per_class = num_per_class\n",
    "        self.num_cl = num_cl\n",
    "        self.num_inst = num_inst\n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # return a single list of indices, assuming that items will be grouped by class\\n\",\n",
    "        if self.shuffle:\n",
    "            batch = [[i+j*self.num_inst for i in torch.randperm(self.num_inst)[:self.num_per_class]] for j in range(self.num_cl)]\n",
    "        else:\n",
    "            batch = [[i+j*self.num_inst for i in range(self.num_inst)[:self.num_per_class]] for j in range(self.num_cl)]\n",
    "        batch = [item for sublist in batch for item in sublist]\n",
    "        if self.shuffle:\n",
    "            random.shuffle(batch)\n",
    "        return iter(batch)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "def get_mini_imagenet_data_loader(task, num_per_class=1, split='train',shuffle = False):\n",
    "    # dataset = MiniImagenet(task,split=split,transform=transforms.Compose([transforms.ToTensor()]))\n",
    "    dataset = MiniImagenet(task,split=split)\n",
    "    if split == 'train':\n",
    "        sampler = ClassBalancedSampler(num_per_class,task.num_classes, task.train_num,shuffle=shuffle)\n",
    "    \n",
    "    else:\n",
    "        sampler = ClassBalancedSampler(num_per_class,task.num_classes, task.test_num,shuffle=shuffle)\n",
    "    # num_workers = (CPU core / GPU core) - 2\n",
    "    loader = DataLoader(dataset, batch_size=num_per_class*task.num_classes, sampler=sampler, pin_memory = True, num_workers=10)\n",
    "    return loader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0*np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
    "    return m,h\n",
    "    \n",
    "class CNNEncoder(nn.Module):\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=2,out_channels=64,kernel_size=3,padding=0),\n",
    "                        nn.BatchNorm2d(num_features=64, momentum=1, affine=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "                        nn.Conv2d(64,64,kernel_size=3,padding=0),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU())\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        # print('CNN Layer 1 out is {}'.format(out.shape))\n",
    "        out = self.layer2(out)\n",
    "        # print('CNN Layer 2 out is {}'.format(out.shape))\n",
    "        out = self.layer3(out)\n",
    "        # print('CNN Layer 3 out is {}'.format(out.shape))\n",
    "        out = self.layer4(out)\n",
    "        # print('CNN Layer 4 out is {}'.format(out.shape))\n",
    "        #out = out.view(out.size(0),-1)\n",
    "        # print(out.shape)\n",
    "        return out # 64\n",
    "\n",
    "class RelationNetwork(nn.Module):\n",
    "    \"\"\"docstring for RelationNetwork\"\"\"\n",
    "    def __init__(self,input_size,hidden_size):\n",
    "        super(RelationNetwork, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(64*2,64,kernel_size=3,padding=0),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "                        nn.Conv2d(64,64,kernel_size=3,padding=0),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2))\n",
    "        self.fc1 = nn.Linear(input_size*3*3,hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        # out = out.view(-1,64) # wjy\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = torch.sigmoid(self.fc2(out))\n",
    "        # print(out.shape)\n",
    "        return out\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        n = m.weight.size(1)\n",
    "        m.weight.data.normal_(0, 0.01)\n",
    "        m.bias.data = torch.ones(m.bias.data.size())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Hyper Parameters\n",
    "FEATURE_DIM = 64\n",
    "RELATION_DIM = 8\n",
    "CLASS_NUM = 5 # way\n",
    "SAMPLE_NUM_PER_CLASS = 1 # shot\n",
    "BATCH_NUM_PER_CLASS = 15 # support?\n",
    "EPISODE = 500000\n",
    "TEST_EPISODE = 600\n",
    "LEARNING_RATE = 0.001\n",
    "GPU = 1\n",
    "HIDDEN_UNIT = 10\n",
    "\n",
    "# TRAIN_NUM = 6\n",
    "TRAIN_NUM = 12\n",
    "VALID_NUM = 6\n",
    "TEST_NUM = 6\n",
    "snr = 18\n",
    "sampling_size = 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "mods = ['OOK', '4ASK', '8ASK', 'BPSK', 'QPSK', '8PSK', '16PSK', '32PSK', '16APSK', '32APSK', '64APSK', '128APSK',\n",
    "'16QAM', '32QAM', '64QAM', '128QAM', '256QAM', 'AM-SSB-WC', 'AM-SSB-SC', 'AM-DSB-WC', 'AM-DSB-SC', 'FM', 'GMSK', 'OQPSK']\n",
    "snrs = [-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30]\n",
    "# classes = ['32PSK','16APSK','32QAM','FM','GMSK','32APSK','OQPSK','8ASK','BPSK','8PSK','AM-SSB-SC','4ASK',\n",
    "# '16PSK','64APSK','128QAM','128APSK','AM-DSB-SC','AM-SSB-WC','64QAM','QPSK','256QAM','AM-DSB-WC','OOK','16QAM']\n",
    "\n",
    "class MyLabelEncoder(LabelEncoder):\n",
    "    def fit(self, y):\n",
    "        y = column_or_1d(y, warn=True)\n",
    "        self.classes_ = pd.Series(y).unique()\n",
    "        return self\n",
    "\n",
    "le = MyLabelEncoder()\n",
    "le.fit(mods)\n",
    "\n",
    "n_mod = len(mods) # 24\n",
    "n_snr = len(snrs) # 26\n",
    "n_samples = 4096\n",
    "len_samples = 1024\n",
    "dir_path = './data/'\n",
    "classes = range(n_mod)\n",
    "\n",
    "with h5py.File(dir_path+str(snr)+\".hdf5\", \"r\") as f:\n",
    "  # I = f.get('I').value\n",
    "  # Q = f.get('Q').value\n",
    "  # IQ = np.stack((I,Q),axis=1) # (98304, 2, 1024)\n",
    "  IQ = np.stack((f.get('I').value,f.get('Q').value),axis=1)\n",
    "  label=(f.get('label').value).reshape(-1)\n",
    "\n",
    "rp = RecurrencePlot(dimension=2, time_delay=940, threshold=None, percentage=10, flatten=False)\n",
    "# image_size = n_timestamps - (dimension - 1) * time_delay\n",
    "\n",
    "# _, sample_IQ, _, sample_label = train_test_split(IQ, label, test_size=n_mod*sampling_size, stratify=label)\n",
    "_, sample_IQ, _, Y = train_test_split(IQ, label, test_size=n_mod*sampling_size, stratify=label)\n",
    "temp = np.split(sample_IQ, 2, axis=1)\n",
    "sample_I = np.array(temp)[0].reshape(-1,len_samples)\n",
    "sample_Q = np.array(temp)[1].reshape(-1,len_samples)\n",
    "rp_I = rp.transform(sample_I)\n",
    "rp_Q = rp.transform(sample_Q)\n",
    "# rp_IQ = np.stack((rp_I,rp_Q),axis=1)\n",
    "# X = rp_IQ\n",
    "X = np.stack((rp_I,rp_Q),axis=1)\n",
    "len_samples = X.shape[2]\n",
    "# Y = le.inverse_transform(np.array(Y, dtype=int))\n",
    "\n",
    "# import collections\n",
    "# print(collections.Counter(sample_label))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-5-a50b042f5d1d>:26: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  IQ = np.stack((f.get('I').value,f.get('Q').value),axis=1)\n",
      "<ipython-input-5-a50b042f5d1d>:27: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  label=(f.get('label').value).reshape(-1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Step 1: init data folders\n",
    "# init neural networks\n",
    "metatrain_folders, metavalid_folders, metatest_folders = mini_imagenet_folders() # load folder root\n",
    "# metatrain_folders, metatest_folders = mini_imagenet_folders() # load folder root\n",
    "\n",
    "# Step 2: init neural networks\n",
    "feature_encoder = CNNEncoder()\n",
    "relation_network = RelationNetwork(FEATURE_DIM,RELATION_DIM)\n",
    "\n",
    "feature_encoder.apply(weights_init)\n",
    "relation_network.apply(weights_init)\n",
    "\n",
    "feature_encoder.cuda(GPU)\n",
    "relation_network.cuda(GPU)\n",
    "\n",
    "feature_encoder_optim = torch.optim.Adam(feature_encoder.parameters(),lr=LEARNING_RATE)\n",
    "feature_encoder_scheduler = StepLR(feature_encoder_optim,step_size=100000,gamma=0.5)\n",
    "relation_network_optim = torch.optim.Adam(relation_network.parameters(),lr=LEARNING_RATE)\n",
    "relation_network_scheduler = StepLR(relation_network_optim,step_size=100000,gamma=0.5)\n",
    "\n",
    "if os.path.exists(str(\"./models/miniimagenet_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")):\n",
    "    feature_encoder.load_state_dict(torch.load(str(\"./models/miniimagenet_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")))\n",
    "    print(\"load feature encoder success\")\n",
    "if os.path.exists(str(\"./models/miniimagenet_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")):\n",
    "    relation_network.load_state_dict(torch.load(str(\"./models/miniimagenet_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")))\n",
    "    print(\"load relation network success\")\n",
    "    \n",
    "# Step 3: build graph\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "# print(\"Training...\")\n",
    "\n",
    "last_accuracy = 0.0\n",
    "for episode in range(EPISODE):\n",
    "    feature_encoder_scheduler.step(episode)\n",
    "    relation_network_scheduler.step(episode)\n",
    "\n",
    "    task = MiniImagenetTask(metatrain_folders,CLASS_NUM,SAMPLE_NUM_PER_CLASS,BATCH_NUM_PER_CLASS)\n",
    "    sample_dataloader = get_mini_imagenet_data_loader(task,num_per_class=SAMPLE_NUM_PER_CLASS,split=\"train\",shuffle=False)\n",
    "    batch_dataloader = get_mini_imagenet_data_loader(task,num_per_class=BATCH_NUM_PER_CLASS,split=\"test\",shuffle=True)\n",
    "\n",
    "    samples,sample_labels = sample_dataloader.__iter__().next() #25*3*84*84\n",
    "    # print('sample shape is {}'.format(samples.shape))\n",
    "    batches,batch_labels = batch_dataloader.__iter__().next()\n",
    "    # print('batch shape is {}'.format(batches.shape))\n",
    "\n",
    "\n",
    "    # calculate features\n",
    "    sample_features = feature_encoder(Variable(samples).cuda(GPU)) # 25*64*19*19\n",
    "    batch_features = feature_encoder(Variable(batches).cuda(GPU)) # 20x64*5*5\n",
    "\n",
    "    # calculate relations\n",
    "    # each batch sample link to every samples to calculate relations\n",
    "    # to form a 100x128 matrix for relation network\n",
    "    sample_features_ext = sample_features.unsqueeze(0).repeat(BATCH_NUM_PER_CLASS*CLASS_NUM,1,1,1,1)\n",
    "    batch_features_ext = batch_features.unsqueeze(0).repeat(SAMPLE_NUM_PER_CLASS*CLASS_NUM,1,1,1,1)\n",
    "    batch_features_ext = torch.transpose(batch_features_ext,0,1)\n",
    "    relation_pairs = torch.cat((sample_features_ext,batch_features_ext),2).view(-1,FEATURE_DIM*2,19,19)\n",
    "    relations = relation_network(relation_pairs).view(-1,CLASS_NUM*SAMPLE_NUM_PER_CLASS)\n",
    "\n",
    "    mse = nn.MSELoss().cuda(GPU)\n",
    "    # one_hot_labels = Variable(torch.zeros(BATCH_NUM_PER_CLASS*CLASS_NUM, CLASS_NUM).scatter_(1, batch_labels.view(-1,1), 1)).cuda(GPU)\n",
    "    one_hot_labels = Variable(torch.tensor(enc.fit_transform(batch_labels.view(-1, 1)).toarray())).float().cuda(GPU)\n",
    "    # print(one_hot_labels.shape)\n",
    "    loss = mse(relations,one_hot_labels)\n",
    "\n",
    "    # training\n",
    "    feature_encoder.zero_grad()\n",
    "    relation_network.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm(feature_encoder.parameters(),0.5)\n",
    "    torch.nn.utils.clip_grad_norm(relation_network.parameters(),0.5)\n",
    "\n",
    "    feature_encoder_optim.step()\n",
    "    relation_network_optim.step()\n",
    "\n",
    "\n",
    "    if (episode+1)%5000 == 0:\n",
    "            print(\"episode:\",episode+1,\"loss\",loss.item())\n",
    "\n",
    "    if episode%5000 == 0:\n",
    "        # test\n",
    "        # print(\"Testing...\")\n",
    "        accuracies = []\n",
    "        for i in range(TEST_EPISODE):\n",
    "            total_rewards = 0\n",
    "            counter = 0\n",
    "            # task = MiniImagenetTask(metatest_folders,CLASS_NUM,SAMPLE_NUM_PER_CLASS,SAMPLE_NUM_PER_CLASS)\n",
    "            task = MiniImagenetTask(metavalid_folders,CLASS_NUM,SAMPLE_NUM_PER_CLASS,SAMPLE_NUM_PER_CLASS)\n",
    "            \n",
    "            sample_dataloader = get_mini_imagenet_data_loader(task,num_per_class=1,split=\"train\",shuffle=False)\n",
    "            test_dataloader = get_mini_imagenet_data_loader(task,SAMPLE_NUM_PER_CLASS,split=\"test\",shuffle=True)\n",
    "            \n",
    "            sample_images,sample_labels = sample_dataloader.__iter__().next()\n",
    "            for test_images,test_labels in test_dataloader:\n",
    "                batch_size = test_labels.shape[0]\n",
    "                # calculate features\n",
    "                sample_features = feature_encoder(Variable(sample_images).cuda(GPU)) # 5x64\n",
    "                test_features = feature_encoder(Variable(test_images).cuda(GPU)) # 20x64\n",
    "\n",
    "                # calculate relations\n",
    "                # each batch sample link to every samples to calculate relations\n",
    "                # to form a 100x128 matrix for relation network\n",
    "                sample_features_ext = sample_features.unsqueeze(0).repeat(batch_size,1,1,1,1)\n",
    "                test_features_ext = test_features.unsqueeze(0).repeat(1*CLASS_NUM,1,1,1,1)\n",
    "                test_features_ext = torch.transpose(test_features_ext,0,1)\n",
    "                relation_pairs = torch.cat((sample_features_ext,test_features_ext),2).view(-1,FEATURE_DIM*2,19,19)\n",
    "                relations = relation_network(relation_pairs).view(-1,CLASS_NUM)\n",
    "\n",
    "                _,predict_labels = torch.max(relations.data,1)\n",
    "                # print(predict_labels)\n",
    "                # print(test_labels)\n",
    "\n",
    "                rewards = [1 if predict_labels[j]==test_labels[j] else 0 for j in range(batch_size)]\n",
    "\n",
    "                total_rewards += np.sum(rewards)\n",
    "                counter += batch_size\n",
    "\n",
    "            accuracy = total_rewards/1.0/counter\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "        test_accuracy,h = mean_confidence_interval(accuracies)\n",
    "\n",
    "        print(\"test accuracy:\",test_accuracy,\"h:\",h)\n",
    "\n",
    "        if test_accuracy > last_accuracy:\n",
    "\n",
    "            # save networks\n",
    "            torch.save(feature_encoder.state_dict(),str(\"./models/miniimagenet_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n",
    "            torch.save(relation_network.state_dict(),str(\"./models/miniimagenet_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n",
    "\n",
    "            print(\"save networks for episode:\",episode)\n",
    "\n",
    "            last_accuracy = test_accuracy"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test accuracy: 0.19233333333333336 h: 0.022122918809038\n",
      "save networks for episode: 0\n",
      "test accuracy: 0.18799999999999997 h: 0.02718716088249977\n",
      "test accuracy: 0.19699999999999998 h: 0.026296444584585826\n",
      "save networks for episode: 10000\n",
      "test accuracy: 0.23233333333333334 h: 0.028312397130955534\n",
      "save networks for episode: 15000\n",
      "test accuracy: 0.257 h: 0.030126395350639986\n",
      "save networks for episode: 20000\n",
      "test accuracy: 0.36333333333333334 h: 0.03178742256345722\n",
      "save networks for episode: 25000\n",
      "test accuracy: 0.5156666666666667 h: 0.030900530222644697\n",
      "save networks for episode: 30000\n",
      "test accuracy: 0.587 h: 0.029595933015819673\n",
      "save networks for episode: 35000\n",
      "test accuracy: 0.7896666666666666 h: 0.024263266562356105\n",
      "save networks for episode: 40000\n",
      "test accuracy: 0.8586666666666666 h: 0.022144786073730976\n",
      "save networks for episode: 45000\n",
      "test accuracy: 0.9136666666666667 h: 0.01727514979874564\n",
      "save networks for episode: 50000\n",
      "test accuracy: 0.8986666666666667 h: 0.01772617736994118\n",
      "test accuracy: 0.8436666666666667 h: 0.02105189078261573\n",
      "test accuracy: 0.7260000000000001 h: 0.023982650130518052\n",
      "test accuracy: 0.6303333333333334 h: 0.02638065261816763\n",
      "test accuracy: 0.6370000000000001 h: 0.028336242067963063\n",
      "test accuracy: 0.6829999999999999 h: 0.027530976453393315\n",
      "test accuracy: 0.7196666666666667 h: 0.027503936326598834\n",
      "test accuracy: 0.737 h: 0.02776233130680666\n",
      "test accuracy: 0.7433333333333333 h: 0.026741344251854943\n",
      "test accuracy: 0.7859999999999998 h: 0.0259529802588389\n",
      "test accuracy: 0.7853333333333333 h: 0.025092790672782035\n",
      "test accuracy: 0.7919999999999999 h: 0.026002389213775217\n",
      "test accuracy: 0.825 h: 0.023012247794569052\n",
      "test accuracy: 0.8160000000000001 h: 0.02378764919586065\n",
      "test accuracy: 0.7813333333333332 h: 0.026181172758044685\n",
      "test accuracy: 0.813 h: 0.024554037866320908\n",
      "test accuracy: 0.8390000000000001 h: 0.022239681807781693\n",
      "test accuracy: 0.8113333333333334 h: 0.024846085615290014\n",
      "test accuracy: 0.82 h: 0.024741568226233128\n",
      "test accuracy: 0.8216666666666667 h: 0.02391182813165996\n",
      "test accuracy: 0.834 h: 0.023021899302466193\n",
      "test accuracy: 0.8386666666666667 h: 0.023436893750763615\n",
      "test accuracy: 0.837 h: 0.023898419925342824\n",
      "test accuracy: 0.854 h: 0.02239428569541761\n",
      "test accuracy: 0.8526666666666666 h: 0.022452993439211852\n",
      "test accuracy: 0.8546666666666666 h: 0.022783043599775222\n",
      "test accuracy: 0.856 h: 0.02216984302737193\n",
      "test accuracy: 0.8793333333333332 h: 0.020756128212470696\n",
      "test accuracy: 0.8623333333333333 h: 0.021338677433770988\n",
      "test accuracy: 0.8576666666666665 h: 0.022383340760744275\n",
      "test accuracy: 0.8559999999999999 h: 0.022169843027371933\n",
      "test accuracy: 0.8596666666666666 h: 0.02207902209446598\n",
      "test accuracy: 0.854 h: 0.022698916503906413\n",
      "test accuracy: 0.8690000000000001 h: 0.02172610450624787\n",
      "test accuracy: 0.8566666666666667 h: 0.02252400309482896\n",
      "test accuracy: 0.8546666666666666 h: 0.022536768690776275\n",
      "test accuracy: 0.8856666666666666 h: 0.019402023922516595\n",
      "test accuracy: 0.8559999999999999 h: 0.02230497210298117\n",
      "test accuracy: 0.8813333333333333 h: 0.020392879299187976\n",
      "test accuracy: 0.854 h: 0.02252806854713564\n",
      "test accuracy: 0.864 h: 0.02239716084926317\n",
      "test accuracy: 0.884 h: 0.019569910285333773\n",
      "test accuracy: 0.8553333333333334 h: 0.0228103478981319\n",
      "test accuracy: 0.8659999999999999 h: 0.021795887981901022\n",
      "test accuracy: 0.8666666666666667 h: 0.021425157012211392\n",
      "test accuracy: 0.8436666666666668 h: 0.023315923729342665\n",
      "test accuracy: 0.8713333333333333 h: 0.020756955468447923\n",
      "test accuracy: 0.8676666666666667 h: 0.021594642334088116\n",
      "test accuracy: 0.8579999999999999 h: 0.02234900125191492\n",
      "test accuracy: 0.8813333333333333 h: 0.02022377652145081\n",
      "test accuracy: 0.8620000000000001 h: 0.02185175075660457\n",
      "test accuracy: 0.871 h: 0.021000714516472833\n",
      "test accuracy: 0.8579999999999999 h: 0.023160212640691392\n",
      "test accuracy: 0.86 h: 0.022978412240687095\n",
      "test accuracy: 0.8779999999999999 h: 0.02024463821139743\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # Hyper Parameters\n",
    "# FEATURE_DIM = 64\n",
    "# RELATION_DIM = 8\n",
    "# CLASS_NUM = 5 # way\n",
    "# SAMPLE_NUM_PER_CLASS = 1 # shot\n",
    "# BATCH_NUM_PER_CLASS = 15 # support?\n",
    "EPISODE = 10\n",
    "TEST_EPISODE = 1000\n",
    "# LEARNING_RATE = 0.001\n",
    "# GPU = 1\n",
    "# HIDDEN_UNIT = 10\n",
    "\n",
    "# TRAIN_NUM = 6\n",
    "# TRAIN_NUM = 14\n",
    "# VALID_NUM = 5\n",
    "# TEST_NUM = 5\n",
    "# snr = 30\n",
    "# sampling_size = 1000\n",
    "\n",
    "# # metatrain_folders,metatest_folders = mini_imagenet_folders()\n",
    "# metatrain_folders, metavalid_folders, metatest_folders = mini_imagenet_folders() # load folder root\n",
    "\n",
    "feature_encoder = CNNEncoder()\n",
    "relation_network = RelationNetwork(FEATURE_DIM,RELATION_DIM)\n",
    "\n",
    "feature_encoder.cuda(GPU)\n",
    "relation_network.cuda(GPU)\n",
    "\n",
    "feature_encoder_optim = torch.optim.Adam(feature_encoder.parameters(),lr=LEARNING_RATE)\n",
    "feature_encoder_scheduler = StepLR(feature_encoder_optim,step_size=100000,gamma=0.5)\n",
    "relation_network_optim = torch.optim.Adam(relation_network.parameters(),lr=LEARNING_RATE)\n",
    "relation_network_scheduler = StepLR(relation_network_optim,step_size=100000,gamma=0.5)\n",
    "\n",
    "if os.path.exists(str(\"./models/miniimagenet_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")):\n",
    "    feature_encoder.load_state_dict(torch.load(str(\"./models/miniimagenet_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")))\n",
    "    print(\"load feature encoder success\")\n",
    "if os.path.exists(str(\"./models/miniimagenet_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")):\n",
    "    relation_network.load_state_dict(torch.load(str(\"./models/miniimagenet_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")))\n",
    "    print(\"load relation network success\")\n",
    "\n",
    "total_accuracy = 0.0\n",
    "for episode in range(EPISODE):\n",
    "    accuracies = []\n",
    "    for i in range(TEST_EPISODE):\n",
    "        total_rewards = 0\n",
    "        counter = 0\n",
    "        task = MiniImagenetTask(metatest_folders,CLASS_NUM,SAMPLE_NUM_PER_CLASS,SAMPLE_NUM_PER_CLASS)\n",
    "        sample_dataloader = get_mini_imagenet_data_loader(task,num_per_class=1,split=\"train\",shuffle=False)\n",
    "        test_dataloader = get_mini_imagenet_data_loader(task,SAMPLE_NUM_PER_CLASS,split=\"test\",shuffle=True)\n",
    "        \n",
    "        sample_images,sample_labels = sample_dataloader.__iter__().next()\n",
    "        for test_images,test_labels in test_dataloader:\n",
    "            batch_size = test_labels.shape[0]\n",
    "\n",
    "            sample_features = feature_encoder(Variable(sample_images).cuda(GPU)) # 5x64\n",
    "            test_features = feature_encoder(Variable(test_images).cuda(GPU)) # 20x64\n",
    "\n",
    "            sample_features_ext = sample_features.unsqueeze(0).repeat(batch_size,1,1,1,1)\n",
    "            test_features_ext = test_features.unsqueeze(0).repeat(1*CLASS_NUM,1,1,1,1)\n",
    "            test_features_ext = torch.transpose(test_features_ext,0,1)\n",
    "            relation_pairs = torch.cat((sample_features_ext,test_features_ext),2).view(-1,FEATURE_DIM*2,19,19)\n",
    "            relations = relation_network(relation_pairs).view(-1,CLASS_NUM)\n",
    "\n",
    "            _,predict_labels = torch.max(relations.data,1)\n",
    "\n",
    "            rewards = [1 if predict_labels[j]==test_labels[j] else 0 for j in range(batch_size)]\n",
    "\n",
    "            total_rewards += np.sum(rewards)\n",
    "            counter += batch_size\n",
    "\n",
    "        accuracy = total_rewards/1.0/counter\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    test_accuracy,h = mean_confidence_interval(accuracies)\n",
    "    print(\"test accuracy:\",test_accuracy,\"h:\",h)\n",
    "    total_accuracy += test_accuracy\n",
    "\n",
    "print(\"aver_accuracy:\",total_accuracy/EPISODE)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test accuracy: 0.8164 h: 0.015742259289923437\n",
      "test accuracy: 0.8192 h: 0.01577898452468244\n",
      "test accuracy: 0.8348 h: 0.015417897283453195\n",
      "test accuracy: 0.8400000000000001 h: 0.014660649748674218\n",
      "test accuracy: 0.8232 h: 0.015169993786858568\n",
      "test accuracy: 0.8238000000000001 h: 0.015130786888387145\n",
      "test accuracy: 0.8268 h: 0.015228323784046106\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7074c9e40daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mtotal_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMiniImagenetTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetatest_folders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCLASS_NUM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSAMPLE_NUM_PER_CLASS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSAMPLE_NUM_PER_CLASS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0msample_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mini_imagenet_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_per_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mini_imagenet_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSAMPLE_NUM_PER_CLASS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4684db0973a7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, character_folders, num_classes, train_num, test_num)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# print(sample_idx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;31m# print(samples.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "529f559a840b978ff77eb1c67cc7c71dfa81432226efdcdc6b9b21e024aa50d9"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}